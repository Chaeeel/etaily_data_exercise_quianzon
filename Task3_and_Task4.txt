[Task # 3 Table Design]
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
From the data that you got from task#2, imagine reading millions or billions of rows from it. Describe a way on how you will design the table so that processing or querying the table will be optimized.
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Query optimization is not an easy task if we are talking about millions or if not, billions of rows of different types of datasets. That is why in designing a table, one must be really careful in doing so for this is a very crucial part of handling data. If I am to be tasked to design a table wherein the processing or querying will be optimized, here are some of the factors that I will be considering:

Choosing the right database engine
	- There are lots of database engines that are freely available for us to use and when we are dealing with millions or billions of rows then of course we would want a database engine that has the capability to handle very large datasets efficiently. Some of these database engines include MySQL, Microsoft SQL Server, and NoSQL databases such as MongoDB and many more. Of course, the choice will depend on the specific requirements of one's application that is why choosing the right database engine should always be considered.

Normalization of data
	- In order for our data to avoid redundancy and improve its data integrity, we must make sure to normalize it. Data Normalization involves breaking the data into smaller, and more manageable tables and establishing relationships between these tables.

Denormalization of data
	- In some cases, denormalization of data might be also beneficial for the pre-aggregate information to reduce the number of joins that are required in complex queries which will undoubtly speed up the query execution. However, it might increase storage requirements and complexity during data updates.

Data Archiving
	- We must make sure to regularly archive or purge historical or unnecessary data to keep the table size manageable and improve query execution and performance.

--------------------------------------------------------------------------------------------------------------------------------------------------------------------------



[Task # 4 Data Pipeline Design in Cloud Setup]
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Assuming you want to deploy an automated solution for task#2 in a cloud setup to be available to an end user via a BI platform. Give a short high level description of a possible approach and some considerations that would affect your choices.
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Choosing of a cloud platform
	- Select a cloud platform that fits your requirements. Popular options include Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform (GCP), and others.

Create a Virtual Machine or container
	- Create a virtual machine or container instance on the cloud platform where you will be running the Python script. VMs are suitable for long-running tasks, while containers (e.g., Docker) provide more lightweight and scalable options.

Dependency installation
	- Make sure that the necessary dependencies and libraries are installed on the VM or container.

Python script upload
	- Upload your Python script and any configuration files to the cloud instance.

Execution and scheduling
	- You can trigger the script execution manually on the cloud instance to test if everything is set up properly.
	- You can also use scheduling services provided by the cloud platform.

Logging
	- Make sure to implement logging in you Python script for you to track its execution and potential errors during executions and help you monitor your script.

Results handling
	- Now you decide how you want to handle the results generated by your Python script. (e.g., saving in database, store them in cloud storage, etc.)

Security
	- Security measures should be implemented in a proper manner for your cloud setup. (e.g., access controls, encryptions, and authentications)

















